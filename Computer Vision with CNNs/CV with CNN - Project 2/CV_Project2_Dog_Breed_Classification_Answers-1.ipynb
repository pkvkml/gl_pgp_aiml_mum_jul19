{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_Project2_Dog_Breed_Classification_Answers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2kIWaR5ZpKlJ"
      },
      "source": [
        "## Dog Breed Classification\n",
        "\n",
        "In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F7MDmaAw2xGO"
      },
      "source": [
        "### Load Dataset Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDdD91ph-eUT",
        "colab_type": "code",
        "outputId": "bc72f24f-eb73-4200-c136-b5592ce44a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1q2zzIaUprk_"
      },
      "source": [
        "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tp6FvAToxUFs",
        "colab": {}
      },
      "source": [
        "project_path = \"/content/drive/My Drive/dog-breed-identification/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rydR_j8lqUei"
      },
      "source": [
        "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3350WZM4w4EL",
        "colab": {}
      },
      "source": [
        "#Commenting the below code as the Files are already in unzipped Format\n",
        "#from zipfile import ZipFile\n",
        "#with ZipFile(project_path+'train.zip', 'r') as z:\n",
        "#  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NHq1iBCfFjE",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for test.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_fxzynvB2YCb",
        "colab": {}
      },
      "source": [
        "#It's already in unzipped Format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnUMhQrDfJmz",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for sample_submission.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4PyTxE8q2jLf",
        "colab": {}
      },
      "source": [
        "#It's already in unzipped Format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G9RIxB-fOLT",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for labels.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rXtnEoEixbgi",
        "colab": {}
      },
      "source": [
        "#It's already in unzipped Format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJc1lVrW_jmL",
        "colab_type": "text"
      },
      "source": [
        "After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aYmJKmDqqpng"
      },
      "source": [
        "### Read labels.csv file using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmlJ2VMY96IZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPvb1RSc96If",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_df = pd.read_csv(project_path + 'labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QP8YAzQvqyK-"
      },
      "source": [
        "### Print the count of each category of Dogs given in the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L2naXlr96Im",
        "colab_type": "code",
        "outputId": "7dc565aa-d928-46cd-f001-68eb6715cdb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "labels_df['breed'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scottish_deerhound      126\n",
              "maltese_dog             117\n",
              "afghan_hound            116\n",
              "entlebucher             115\n",
              "bernese_mountain_dog    114\n",
              "                       ... \n",
              "golden_retriever         67\n",
              "brabancon_griffon        67\n",
              "komondor                 67\n",
              "briard                   66\n",
              "eskimo_dog               66\n",
              "Name: breed, Length: 120, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WI94_Qcc0D4M"
      },
      "source": [
        "### Get one-hot encodings of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q48iAcY196I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nlWmRNM96I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.array(pd.get_dummies(labels_df['breed']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWaJ9naXfoiU",
        "colab_type": "text"
      },
      "source": [
        "## Preparing training dataset\n",
        "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
        "2. Create 2 variables <br> \n",
        "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
        "     b.  y_train - Corresponding label of the dog <br>\n",
        "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
        "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBNifcAuFvrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows = 128\n",
        "img_columns = 128\n",
        "num_channels = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aC2f9ecR0XGR",
        "outputId": "0c69bb5b-96b5-4a94-bfec-a51c4268a8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "import cv2\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i, breed in tqdm(labels_df.values):\n",
        "  train_img = cv2.imread(project_path + 'train/{}.jpg'.format(i), 1)\n",
        "  train_img_resize = cv2.resize(train_img, (img_rows, img_columns))\n",
        "  x_train.append(train_img_resize)\n",
        "  y_train.append(breed)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10222/10222 [01:22<00:00, 124.20it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ioWDEgElBOs",
        "colab_type": "text"
      },
      "source": [
        "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ARn76j3U1CDa",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_train = x_train / 255\n",
        "\n",
        "x_train = np.reshape(x_train, (len(x_train), img_rows, img_columns, num_channels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bdCXuAE11gZL"
      },
      "source": [
        "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpWx-pgV96Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(X_train, X_val, y_train, y_val) = train_test_split(x_train, y_train,\ttest_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XkL-N1jDsU8m"
      },
      "source": [
        "### Loading the test data\n",
        "Read the id column from the samples_submission.csv and store it in test_img"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DnpXdpd9b3E7",
        "colab": {}
      },
      "source": [
        "#Commenting out below piece of code as we are not targetting to submit our Model's predictions on Kaggle competition\n",
        "#temp_df = pd.read_csv(project_path + 'sample_submission.csv')\n",
        "#test_img = temp_df['id']\n",
        "#del temp_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEJqZIMbm0Jo",
        "colab_type": "text"
      },
      "source": [
        "Run the below code to load the test image files in x_test_feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zf7n4WG-b3Hv",
        "colab": {}
      },
      "source": [
        "#Commenting out below piece of code as we are not targetting to submit our Model's predictions on Kaggle competition\n",
        "#x_test_feature = []\n",
        "#i = 0 # initialisation\n",
        "#for f in tqdm(test_img.values): # f for format ,jpg\n",
        "#    img = cv2.imread(project_path + 'test/{}.jpg'.format(f), 1)\n",
        "#    img_resize = cv2.resize(img, (img_rows, img_columns)) \n",
        "#    x_test_feature.append(img_resize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9My6qSyDnE-_",
        "colab_type": "text"
      },
      "source": [
        "Normalize the test data and convert it into 4 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93n-IntMnJGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Commenting out below piece of code as we are not targetting to submit our Model's predictions on Kaggle competition\n",
        "#x_test_feature = np.array(x_test_feature)\n",
        "#x_test_feature = x_test_feature / 255\n",
        "#\n",
        "#x_test_feature = np.reshape(x_test_feature, (len(x_test_feature), img_rows, img_columns, num_channels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zKezNJVMsocP"
      },
      "source": [
        "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
        "\n",
        "1. Add a Dense layer with 256 neurons with `relu` activation\n",
        "\n",
        "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYAQETWv_44B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Deleting unwanted variables\n",
        "del labels_df\n",
        "del labels\n",
        "del x_train\n",
        "del i\n",
        "del breed\n",
        "del train_img\n",
        "del train_img_resize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2jxTY2S96J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32,\n",
        "                                 kernel_size=(5,5),\n",
        "                                 activation='relu',\n",
        "                                 input_shape=(img_rows, img_columns, num_channels, )))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32,\n",
        "                                 kernel_size=(3,3),\n",
        "                                 activation='relu'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(120, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_BAvCzo96J6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = pd.get_dummies(y_train)\n",
        "y_val = pd.get_dummies(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoKAseHiN3_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnPPOdvuN8vm",
        "colab_type": "code",
        "outputId": "1d50ccbc-eee6-4922-af53-53287f05f333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 124, 124, 32)      2432      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 122, 122, 32)      9248      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 476288)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               121929984 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 121,972,504\n",
            "Trainable params: 121,972,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8EXw6_oqpR",
        "colab_type": "text"
      },
      "source": [
        "### Use batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IriIc37NozbK",
        "colab_type": "code",
        "outputId": "f13e7e29-8024-4541-8045-c511faef616a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "model.fit(X_train, y_train,          \n",
        "          validation_data=(X_val, y_val),\n",
        "          epochs=10,\n",
        "          batch_size=128)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "64/64 [==============================] - 20s 317ms/step - loss: 6.2816 - accuracy: 0.0114 - val_loss: 4.7685 - val_accuracy: 0.0181\n",
            "Epoch 2/10\n",
            "64/64 [==============================] - 19s 296ms/step - loss: 4.5338 - accuracy: 0.0585 - val_loss: 4.7119 - val_accuracy: 0.0269\n",
            "Epoch 3/10\n",
            "64/64 [==============================] - 19s 296ms/step - loss: 2.8064 - accuracy: 0.3834 - val_loss: 5.6611 - val_accuracy: 0.0225\n",
            "Epoch 4/10\n",
            "64/64 [==============================] - 19s 298ms/step - loss: 0.6666 - accuracy: 0.8605 - val_loss: 8.9726 - val_accuracy: 0.0259\n",
            "Epoch 5/10\n",
            "64/64 [==============================] - 19s 297ms/step - loss: 0.1302 - accuracy: 0.9817 - val_loss: 9.7725 - val_accuracy: 0.0279\n",
            "Epoch 6/10\n",
            "64/64 [==============================] - 19s 298ms/step - loss: 0.0656 - accuracy: 0.9933 - val_loss: 10.7911 - val_accuracy: 0.0352\n",
            "Epoch 7/10\n",
            "64/64 [==============================] - 19s 298ms/step - loss: 0.0331 - accuracy: 0.9966 - val_loss: 10.8887 - val_accuracy: 0.0337\n",
            "Epoch 8/10\n",
            "64/64 [==============================] - 19s 299ms/step - loss: 0.0274 - accuracy: 0.9980 - val_loss: 11.2475 - val_accuracy: 0.0313\n",
            "Epoch 9/10\n",
            "64/64 [==============================] - 19s 299ms/step - loss: 0.0247 - accuracy: 0.9982 - val_loss: 10.3898 - val_accuracy: 0.0308\n",
            "Epoch 10/10\n",
            "64/64 [==============================] - 19s 299ms/step - loss: 0.0208 - accuracy: 0.9980 - val_loss: 11.1914 - val_accuracy: 0.0303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29405a0ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8hWaKmjoz69",
        "colab_type": "text"
      },
      "source": [
        "#The model accuracy is very poor !!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "agJKkc6xtKiq"
      },
      "source": [
        "### Use Data Augmentation in the above model to see if the accuracy improves\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "31Mn8qnZb3Ru",
        "colab": {}
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
        "                                                                width_shift_range=0.2,\n",
        "                                                                height_shift_range=0.2,\n",
        "                                                                horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDLQVFDP96KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sssbaTfxlkk"
      },
      "source": [
        "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
        "\n",
        "You need to use train_datagen.flow() and val_datagen.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sehaRgT-96KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=128)\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVFQJZw3x4-C"
      },
      "source": [
        "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J1K2MqHbuPUa",
        "outputId": "2c8d827c-1219-4e16-c19a-eb0c32ac63d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "model.fit_generator(train_generator,\n",
        "                    epochs = 10,\n",
        "                    steps_per_epoch = len(X_train) // 128,\n",
        "                    validation_data = val_generator,\n",
        "                    validation_steps = len(X_val) // 128)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-28-f8146b9402fa>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "63/63 [==============================] - 31s 491ms/step - loss: 4.9606 - accuracy: 0.0140 - val_loss: 4.7556 - val_accuracy: 0.0198\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 31s 489ms/step - loss: 4.7597 - accuracy: 0.0140 - val_loss: 4.7478 - val_accuracy: 0.0177\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 31s 495ms/step - loss: 4.7231 - accuracy: 0.0179 - val_loss: 4.7117 - val_accuracy: 0.0193\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 31s 499ms/step - loss: 4.6884 - accuracy: 0.0211 - val_loss: 4.7291 - val_accuracy: 0.0182\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 31s 490ms/step - loss: 4.6947 - accuracy: 0.0193 - val_loss: 4.6679 - val_accuracy: 0.0193\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 31s 493ms/step - loss: 4.6807 - accuracy: 0.0219 - val_loss: 4.6524 - val_accuracy: 0.0266\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 31s 492ms/step - loss: 4.6305 - accuracy: 0.0245 - val_loss: 4.6109 - val_accuracy: 0.0240\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 31s 488ms/step - loss: 4.6147 - accuracy: 0.0297 - val_loss: 4.6050 - val_accuracy: 0.0234\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 31s 491ms/step - loss: 4.6246 - accuracy: 0.0273 - val_loss: 4.6111 - val_accuracy: 0.0292\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 31s 494ms/step - loss: 4.5856 - accuracy: 0.0311 - val_loss: 4.6229 - val_accuracy: 0.0276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29402d0588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2zmLztqo5DY",
        "colab_type": "text"
      },
      "source": [
        "# Model accuracy is still poor!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkHzZnfCOqlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSTATrhsAo7L",
        "colab_type": "text"
      },
      "source": [
        "### Lets use Transfer Learning\n",
        "\n",
        "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy5JdbW6pIvD",
        "colab_type": "text"
      },
      "source": [
        "Use the below code to load VGG16 weights trained on ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrqs0zg7ApNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "# Instantiate the model with the pre-trained weights (no top)\n",
        "base_model= VGG16(weights=(project_path+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),\n",
        "                 include_top=False, pooling='avg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EItOlRBGpV_A",
        "colab_type": "text"
      },
      "source": [
        "Print the summary of the base_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQsEBgnlpHjH",
        "colab_type": "code",
        "outputId": "3c45a711-cddd-4ffa-bd5b-b73c151e2b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHpeOyW0qauW",
        "colab_type": "text"
      },
      "source": [
        "### Add the following classification layers to the imported VGG Model <br>\n",
        "1. Flatten Layer\n",
        "2. Dense layer with 1024 neurons with activation as Relu\n",
        "3. Dense layer with 256 neurons with activation as Relu\n",
        "4. Dense layer with 120 neurons with activation as Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BpT4MLkqoaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.keras.layers.Flatten()(base_model.output)\n",
        "\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "x = tf.keras.layers.Dense(120, activation='softmax')(x)\n",
        "\n",
        "final_model = tf.keras.models.Model(inputs=base_model.input, #Pre-trained model input as input layer\n",
        "                                    outputs=x) #Output layer added"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeQem0pHITIj",
        "colab_type": "text"
      },
      "source": [
        "### Make all the layers in the base_model (VGG16) to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5odyphDOEd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set pre-trained model layers to not trainable\n",
        "for layer in final_model.layers[:20]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7w9CSPvIRnX",
        "colab_type": "code",
        "outputId": "b8be9b3f-b795-416f-ae57-68478c62b6db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "final_model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 15,533,240\n",
            "Trainable params: 818,552\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj-BwqgfIkdv",
        "colab_type": "text"
      },
      "source": [
        "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD5fAgVQIpKZ",
        "colab_type": "text"
      },
      "source": [
        "Try to get training and validation accuracy to be more than 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHQU3zYmMlyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_model.compile(optimizer='adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZk2SWvjIoRP",
        "colab_type": "code",
        "outputId": "b5531d62-8f5c-4e00-bbf4-50dab4d344a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "final_model.fit_generator(train_generator,\n",
        "                    epochs = 10,\n",
        "                    steps_per_epoch = len(X_train) // 128,\n",
        "                    validation_data = val_generator,\n",
        "                    validation_steps = len(X_val) // 128)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 40s 638ms/step - loss: 4.7679 - accuracy: 0.0186 - val_loss: 4.6904 - val_accuracy: 0.0339\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 36s 572ms/step - loss: 4.5450 - accuracy: 0.0468 - val_loss: 4.3211 - val_accuracy: 0.0630\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 37s 580ms/step - loss: 4.1316 - accuracy: 0.0885 - val_loss: 3.9685 - val_accuracy: 0.0964\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 36s 576ms/step - loss: 3.8157 - accuracy: 0.1190 - val_loss: 3.8149 - val_accuracy: 0.1063\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 37s 579ms/step - loss: 3.5993 - accuracy: 0.1587 - val_loss: 3.5355 - val_accuracy: 0.1526\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 36s 569ms/step - loss: 3.4759 - accuracy: 0.1763 - val_loss: 3.4466 - val_accuracy: 0.1734\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 36s 577ms/step - loss: 3.3579 - accuracy: 0.1924 - val_loss: 3.3975 - val_accuracy: 0.1792\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 37s 582ms/step - loss: 3.2993 - accuracy: 0.2003 - val_loss: 3.3548 - val_accuracy: 0.1823\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 37s 583ms/step - loss: 3.2056 - accuracy: 0.2204 - val_loss: 3.2905 - val_accuracy: 0.1974\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 36s 564ms/step - loss: 3.1556 - accuracy: 0.2281 - val_loss: 3.3312 - val_accuracy: 0.1927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29401c6208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rVZYzRmZDZ2",
        "colab_type": "code",
        "outputId": "87f8b6fc-14d4-4900-a954-9588094b3b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "final_model.fit_generator(train_generator,\n",
        "                    epochs = 50,\n",
        "                    steps_per_epoch = len(X_train) // 128,\n",
        "                    validation_data = val_generator,\n",
        "                    validation_steps = len(X_val) // 128,\n",
        "                    initial_epoch = 10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "63/63 [==============================] - 36s 565ms/step - loss: 3.1236 - accuracy: 0.2385 - val_loss: 3.2912 - val_accuracy: 0.1964\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 36s 574ms/step - loss: 3.0461 - accuracy: 0.2553 - val_loss: 3.2761 - val_accuracy: 0.2115\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 36s 570ms/step - loss: 3.0347 - accuracy: 0.2479 - val_loss: 3.2615 - val_accuracy: 0.2094\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 35s 557ms/step - loss: 2.9394 - accuracy: 0.2780 - val_loss: 3.2857 - val_accuracy: 0.2203\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 36s 573ms/step - loss: 2.9522 - accuracy: 0.2707 - val_loss: 3.2388 - val_accuracy: 0.2255\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 36s 577ms/step - loss: 2.8848 - accuracy: 0.2797 - val_loss: 3.1727 - val_accuracy: 0.2266\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 36s 570ms/step - loss: 2.8655 - accuracy: 0.2921 - val_loss: 3.2084 - val_accuracy: 0.2260\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 36s 578ms/step - loss: 2.8327 - accuracy: 0.2936 - val_loss: 3.1861 - val_accuracy: 0.2260\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 36s 576ms/step - loss: 2.7848 - accuracy: 0.3019 - val_loss: 3.1701 - val_accuracy: 0.2359\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 36s 577ms/step - loss: 2.7629 - accuracy: 0.3076 - val_loss: 3.1782 - val_accuracy: 0.2313\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 37s 585ms/step - loss: 2.7316 - accuracy: 0.3102 - val_loss: 3.1596 - val_accuracy: 0.2365\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 36s 579ms/step - loss: 2.7083 - accuracy: 0.3176 - val_loss: 3.2047 - val_accuracy: 0.2354\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 36s 565ms/step - loss: 2.6734 - accuracy: 0.3302 - val_loss: 3.1850 - val_accuracy: 0.2328\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 2.6497 - accuracy: 0.3279 - val_loss: 3.2031 - val_accuracy: 0.2422\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 36s 567ms/step - loss: 2.6277 - accuracy: 0.3330 - val_loss: 3.1702 - val_accuracy: 0.2307\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 36s 570ms/step - loss: 2.5828 - accuracy: 0.3403 - val_loss: 3.2359 - val_accuracy: 0.2271\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 35s 561ms/step - loss: 2.5622 - accuracy: 0.3466 - val_loss: 3.1694 - val_accuracy: 0.2458\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 36s 569ms/step - loss: 2.5362 - accuracy: 0.3515 - val_loss: 3.1897 - val_accuracy: 0.2422\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 36s 576ms/step - loss: 2.5107 - accuracy: 0.3629 - val_loss: 3.1575 - val_accuracy: 0.2464\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 35s 560ms/step - loss: 2.4658 - accuracy: 0.3622 - val_loss: 3.1467 - val_accuracy: 0.2474\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 35s 563ms/step - loss: 2.4507 - accuracy: 0.3746 - val_loss: 3.2830 - val_accuracy: 0.2307\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 35s 560ms/step - loss: 2.4279 - accuracy: 0.3819 - val_loss: 3.2263 - val_accuracy: 0.2417\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 36s 575ms/step - loss: 2.4165 - accuracy: 0.3799 - val_loss: 3.1934 - val_accuracy: 0.2438\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 36s 569ms/step - loss: 2.3715 - accuracy: 0.3897 - val_loss: 3.2125 - val_accuracy: 0.2526\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 36s 573ms/step - loss: 2.3636 - accuracy: 0.3855 - val_loss: 3.2267 - val_accuracy: 0.2521\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 37s 582ms/step - loss: 2.3165 - accuracy: 0.4018 - val_loss: 3.2170 - val_accuracy: 0.2469\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 36s 573ms/step - loss: 2.2994 - accuracy: 0.4038 - val_loss: 3.2804 - val_accuracy: 0.2365\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 36s 565ms/step - loss: 2.2824 - accuracy: 0.4107 - val_loss: 3.2498 - val_accuracy: 0.2536\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 36s 570ms/step - loss: 2.2482 - accuracy: 0.4169 - val_loss: 3.2951 - val_accuracy: 0.2385\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 37s 580ms/step - loss: 2.2625 - accuracy: 0.4087 - val_loss: 3.3422 - val_accuracy: 0.2375\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 36s 565ms/step - loss: 2.2213 - accuracy: 0.4215 - val_loss: 3.2160 - val_accuracy: 0.2562\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 36s 564ms/step - loss: 2.1853 - accuracy: 0.4311 - val_loss: 3.2837 - val_accuracy: 0.2401\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 2.1537 - accuracy: 0.4391 - val_loss: 3.2716 - val_accuracy: 0.2458\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 36s 575ms/step - loss: 2.1296 - accuracy: 0.4422 - val_loss: 3.2934 - val_accuracy: 0.2432\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 36s 566ms/step - loss: 2.1158 - accuracy: 0.4495 - val_loss: 3.2788 - val_accuracy: 0.2521\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 37s 585ms/step - loss: 2.1063 - accuracy: 0.4428 - val_loss: 3.2750 - val_accuracy: 0.2526\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 36s 570ms/step - loss: 2.0739 - accuracy: 0.4533 - val_loss: 3.3002 - val_accuracy: 0.2589\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 36s 570ms/step - loss: 2.0647 - accuracy: 0.4573 - val_loss: 3.3807 - val_accuracy: 0.2573\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 36s 564ms/step - loss: 1.9956 - accuracy: 0.4757 - val_loss: 3.3326 - val_accuracy: 0.2443\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 36s 572ms/step - loss: 2.0300 - accuracy: 0.4659 - val_loss: 3.4037 - val_accuracy: 0.2359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29dae51dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PQAgWrBJ6nN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding BatchNormalization Layer & Dropout Layers before Dense layers to check if the model's performance improves\n",
        "\n",
        "x = tf.keras.layers.BatchNormalization()(base_model.output)\n",
        "\n",
        "x = tf.keras.layers.Dropout(0.25)(x)\n",
        "\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = tf.keras.layers.Dropout(0.25)(x)\n",
        "\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = tf.keras.layers.Dropout(0.25)(x)\n",
        "\n",
        "x = tf.keras.layers.Dense(120, activation='softmax')(x)\n",
        "\n",
        "final_model2 = tf.keras.models.Model(inputs=base_model.input, #Pre-trained model input as input layer\n",
        "                                    outputs=x) #Output layer added"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4sx-Ull4QMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set pre-trained model layers to not trainable\n",
        "for layer in final_model2.layers[:20]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB6SgJVG4aqK",
        "colab_type": "code",
        "outputId": "768ec7e7-0c11-466a-eb2d-c20419aa0b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "final_model2.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 15,540,408\n",
            "Trainable params: 822,136\n",
            "Non-trainable params: 14,718,272\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohRyrVB64rgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_model2.compile(optimizer='adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7fOP-Bl4xRi",
        "colab_type": "code",
        "outputId": "464cf647-2599-4af1-a71d-503aa1e979cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "final_model2.fit_generator(train_generator,\n",
        "                    epochs = 50,\n",
        "                    steps_per_epoch = len(X_train) // 128,\n",
        "                    validation_data = val_generator,\n",
        "                    validation_steps = len(X_val) // 128)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "63/63 [==============================] - 37s 581ms/step - loss: 4.9331 - accuracy: 0.0395 - val_loss: 4.5948 - val_accuracy: 0.0495\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 36s 564ms/step - loss: 4.0944 - accuracy: 0.1039 - val_loss: 4.2900 - val_accuracy: 0.1047\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 36s 569ms/step - loss: 3.7157 - accuracy: 0.1579 - val_loss: 3.9781 - val_accuracy: 0.1333\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 36s 571ms/step - loss: 3.5032 - accuracy: 0.1887 - val_loss: 3.6926 - val_accuracy: 0.1776\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 35s 562ms/step - loss: 3.3389 - accuracy: 0.2126 - val_loss: 3.5106 - val_accuracy: 0.1969\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 35s 561ms/step - loss: 3.1923 - accuracy: 0.2383 - val_loss: 3.3451 - val_accuracy: 0.2245\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 35s 563ms/step - loss: 3.0943 - accuracy: 0.2526 - val_loss: 3.2787 - val_accuracy: 0.2271\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 36s 570ms/step - loss: 3.0215 - accuracy: 0.2696 - val_loss: 3.2268 - val_accuracy: 0.2333\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 36s 571ms/step - loss: 2.9539 - accuracy: 0.2785 - val_loss: 3.2454 - val_accuracy: 0.2219\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 35s 559ms/step - loss: 2.9147 - accuracy: 0.2848 - val_loss: 3.2560 - val_accuracy: 0.2224\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 36s 575ms/step - loss: 2.8453 - accuracy: 0.2994 - val_loss: 3.2215 - val_accuracy: 0.2302\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 37s 582ms/step - loss: 2.8078 - accuracy: 0.3008 - val_loss: 3.1952 - val_accuracy: 0.2396\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 37s 580ms/step - loss: 2.7452 - accuracy: 0.3148 - val_loss: 3.2368 - val_accuracy: 0.2313\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 36s 573ms/step - loss: 2.7252 - accuracy: 0.3220 - val_loss: 3.2428 - val_accuracy: 0.2354\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 37s 581ms/step - loss: 2.6485 - accuracy: 0.3392 - val_loss: 3.2403 - val_accuracy: 0.2448\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 36s 579ms/step - loss: 2.6232 - accuracy: 0.3379 - val_loss: 3.2352 - val_accuracy: 0.2464\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 37s 586ms/step - loss: 2.5925 - accuracy: 0.3496 - val_loss: 3.2558 - val_accuracy: 0.2438\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 36s 576ms/step - loss: 2.5702 - accuracy: 0.3530 - val_loss: 3.2618 - val_accuracy: 0.2396\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 36s 571ms/step - loss: 2.4896 - accuracy: 0.3697 - val_loss: 3.2893 - val_accuracy: 0.2458\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 2.4972 - accuracy: 0.3634 - val_loss: 3.2680 - val_accuracy: 0.2536\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 2.4631 - accuracy: 0.3717 - val_loss: 3.2564 - val_accuracy: 0.2469\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 36s 577ms/step - loss: 2.4430 - accuracy: 0.3731 - val_loss: 3.2644 - val_accuracy: 0.2531\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 36s 571ms/step - loss: 2.3813 - accuracy: 0.3873 - val_loss: 3.3118 - val_accuracy: 0.2349\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 2.3971 - accuracy: 0.3856 - val_loss: 3.2723 - val_accuracy: 0.2438\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 36s 575ms/step - loss: 2.3511 - accuracy: 0.3938 - val_loss: 3.2897 - val_accuracy: 0.2448\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 35s 562ms/step - loss: 2.3255 - accuracy: 0.3983 - val_loss: 3.2881 - val_accuracy: 0.2536\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 36s 565ms/step - loss: 2.2792 - accuracy: 0.4183 - val_loss: 3.3248 - val_accuracy: 0.2380\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 36s 566ms/step - loss: 2.2542 - accuracy: 0.4210 - val_loss: 3.3130 - val_accuracy: 0.2505\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 36s 567ms/step - loss: 2.2633 - accuracy: 0.4101 - val_loss: 3.3197 - val_accuracy: 0.2411\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 35s 562ms/step - loss: 2.1853 - accuracy: 0.4356 - val_loss: 3.3272 - val_accuracy: 0.2432\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 35s 563ms/step - loss: 2.1734 - accuracy: 0.4306 - val_loss: 3.3411 - val_accuracy: 0.2536\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 36s 564ms/step - loss: 2.1965 - accuracy: 0.4283 - val_loss: 3.3728 - val_accuracy: 0.2401\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 36s 566ms/step - loss: 2.1100 - accuracy: 0.4479 - val_loss: 3.3969 - val_accuracy: 0.2417\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 36s 570ms/step - loss: 2.1312 - accuracy: 0.4427 - val_loss: 3.3904 - val_accuracy: 0.2406\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 2.1094 - accuracy: 0.4468 - val_loss: 3.3928 - val_accuracy: 0.2432\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 36s 574ms/step - loss: 2.0707 - accuracy: 0.4491 - val_loss: 3.3936 - val_accuracy: 0.2505\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 36s 573ms/step - loss: 2.0700 - accuracy: 0.4500 - val_loss: 3.4110 - val_accuracy: 0.2432\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 36s 567ms/step - loss: 2.0189 - accuracy: 0.4665 - val_loss: 3.4291 - val_accuracy: 0.2443\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 36s 575ms/step - loss: 2.0140 - accuracy: 0.4670 - val_loss: 3.4114 - val_accuracy: 0.2391\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 36s 576ms/step - loss: 1.9765 - accuracy: 0.4781 - val_loss: 3.4368 - val_accuracy: 0.2443\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 35s 562ms/step - loss: 1.9907 - accuracy: 0.4766 - val_loss: 3.4718 - val_accuracy: 0.2479\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 35s 561ms/step - loss: 1.9149 - accuracy: 0.4927 - val_loss: 3.4492 - val_accuracy: 0.2495\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 1.9595 - accuracy: 0.4762 - val_loss: 3.4641 - val_accuracy: 0.2417\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 36s 564ms/step - loss: 1.9226 - accuracy: 0.4915 - val_loss: 3.4374 - val_accuracy: 0.2464\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 36s 565ms/step - loss: 1.8853 - accuracy: 0.4999 - val_loss: 3.4745 - val_accuracy: 0.2500\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 36s 569ms/step - loss: 1.8875 - accuracy: 0.4921 - val_loss: 3.4239 - val_accuracy: 0.2594\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 35s 562ms/step - loss: 1.8547 - accuracy: 0.5044 - val_loss: 3.4863 - val_accuracy: 0.2443\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 36s 571ms/step - loss: 1.8725 - accuracy: 0.5047 - val_loss: 3.4960 - val_accuracy: 0.2484\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 1.8248 - accuracy: 0.5028 - val_loss: 3.5307 - val_accuracy: 0.2474\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 36s 567ms/step - loss: 1.7985 - accuracy: 0.5120 - val_loss: 3.5007 - val_accuracy: 0.2484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f291f892668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX3HnU_JXvej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Making last layer of VGG16 trainable to see if it improves the Model performance\n",
        "final_model2.layers[17].trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeFQ4rjXX7Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_model2.compile(optimizer='adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eccU6ABWYB6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "479606a4-1416-4261-eb50-29d87a564836"
      },
      "source": [
        "final_model2.fit_generator(train_generator,\n",
        "                    epochs = 50,\n",
        "                    steps_per_epoch = len(X_train) // 128,\n",
        "                    validation_data = val_generator,\n",
        "                    validation_steps = len(X_val) // 128)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "63/63 [==============================] - 37s 586ms/step - loss: 2.7807 - accuracy: 0.3243 - val_loss: 4.9298 - val_accuracy: 0.1594\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 36s 575ms/step - loss: 2.3826 - accuracy: 0.3853 - val_loss: 4.3930 - val_accuracy: 0.2052\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 36s 574ms/step - loss: 2.1313 - accuracy: 0.4275 - val_loss: 3.7117 - val_accuracy: 0.2401\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 36s 577ms/step - loss: 1.9582 - accuracy: 0.4679 - val_loss: 3.6661 - val_accuracy: 0.2234\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 36s 571ms/step - loss: 1.8868 - accuracy: 0.4878 - val_loss: 3.4706 - val_accuracy: 0.2448\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 36s 566ms/step - loss: 1.7659 - accuracy: 0.5147 - val_loss: 3.6438 - val_accuracy: 0.2359\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 36s 572ms/step - loss: 1.7042 - accuracy: 0.5201 - val_loss: 3.3691 - val_accuracy: 0.2542\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 36s 575ms/step - loss: 1.6428 - accuracy: 0.5412 - val_loss: 3.3389 - val_accuracy: 0.2698\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 36s 572ms/step - loss: 1.5793 - accuracy: 0.5653 - val_loss: 3.3740 - val_accuracy: 0.2656\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 36s 564ms/step - loss: 1.4825 - accuracy: 0.5775 - val_loss: 3.3363 - val_accuracy: 0.2714\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 37s 584ms/step - loss: 1.4737 - accuracy: 0.5880 - val_loss: 3.3630 - val_accuracy: 0.2786\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 36s 574ms/step - loss: 1.4022 - accuracy: 0.6019 - val_loss: 3.3974 - val_accuracy: 0.2833\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 36s 574ms/step - loss: 1.3963 - accuracy: 0.6036 - val_loss: 3.4515 - val_accuracy: 0.2641\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 36s 574ms/step - loss: 1.3253 - accuracy: 0.6204 - val_loss: 3.3533 - val_accuracy: 0.2812\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 36s 570ms/step - loss: 1.3157 - accuracy: 0.6236 - val_loss: 3.4444 - val_accuracy: 0.2599\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 37s 579ms/step - loss: 1.2596 - accuracy: 0.6380 - val_loss: 3.5101 - val_accuracy: 0.2688\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 36s 573ms/step - loss: 1.2538 - accuracy: 0.6385 - val_loss: 3.5783 - val_accuracy: 0.2750\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 36s 572ms/step - loss: 1.2041 - accuracy: 0.6542 - val_loss: 3.5276 - val_accuracy: 0.2542\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 36s 564ms/step - loss: 1.1569 - accuracy: 0.6658 - val_loss: 3.4897 - val_accuracy: 0.2812\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 36s 567ms/step - loss: 1.1555 - accuracy: 0.6699 - val_loss: 3.5581 - val_accuracy: 0.2734\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 36s 579ms/step - loss: 1.1129 - accuracy: 0.6761 - val_loss: 3.4981 - val_accuracy: 0.2833\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 36s 573ms/step - loss: 1.0981 - accuracy: 0.6864 - val_loss: 3.5624 - val_accuracy: 0.2828\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 36s 572ms/step - loss: 1.0352 - accuracy: 0.7007 - val_loss: 3.6259 - val_accuracy: 0.2818\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 36s 573ms/step - loss: 1.0663 - accuracy: 0.6893 - val_loss: 3.5693 - val_accuracy: 0.2745\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 36s 571ms/step - loss: 0.9911 - accuracy: 0.7099 - val_loss: 3.6194 - val_accuracy: 0.2719\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 37s 580ms/step - loss: 1.0023 - accuracy: 0.7083 - val_loss: 3.5319 - val_accuracy: 0.2792\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 0.9338 - accuracy: 0.7222 - val_loss: 3.6069 - val_accuracy: 0.2708\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 36s 572ms/step - loss: 0.9526 - accuracy: 0.7140 - val_loss: 3.6889 - val_accuracy: 0.2786\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 0.9440 - accuracy: 0.7203 - val_loss: 3.6673 - val_accuracy: 0.2729\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 36s 572ms/step - loss: 0.9024 - accuracy: 0.7287 - val_loss: 3.6614 - val_accuracy: 0.2849\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 36s 569ms/step - loss: 0.8862 - accuracy: 0.7343 - val_loss: 3.6417 - val_accuracy: 0.2807\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 36s 579ms/step - loss: 0.8704 - accuracy: 0.7410 - val_loss: 3.7492 - val_accuracy: 0.2781\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 36s 575ms/step - loss: 0.8949 - accuracy: 0.7390 - val_loss: 3.7109 - val_accuracy: 0.2818\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 36s 567ms/step - loss: 0.8700 - accuracy: 0.7397 - val_loss: 3.8094 - val_accuracy: 0.2807\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 36s 571ms/step - loss: 0.8310 - accuracy: 0.7513 - val_loss: 3.7386 - val_accuracy: 0.2823\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 37s 583ms/step - loss: 0.8264 - accuracy: 0.7546 - val_loss: 3.7827 - val_accuracy: 0.2927\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 36s 568ms/step - loss: 0.7871 - accuracy: 0.7618 - val_loss: 3.7474 - val_accuracy: 0.2880\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 36s 569ms/step - loss: 0.7942 - accuracy: 0.7689 - val_loss: 3.8040 - val_accuracy: 0.2807\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 36s 579ms/step - loss: 0.7996 - accuracy: 0.7627 - val_loss: 3.8088 - val_accuracy: 0.2719\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 37s 591ms/step - loss: 0.7793 - accuracy: 0.7634 - val_loss: 3.8114 - val_accuracy: 0.2906\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 37s 591ms/step - loss: 0.7645 - accuracy: 0.7719 - val_loss: 3.8879 - val_accuracy: 0.2714\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 36s 575ms/step - loss: 0.7452 - accuracy: 0.7767 - val_loss: 3.7632 - val_accuracy: 0.2880\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 37s 581ms/step - loss: 0.7208 - accuracy: 0.7802 - val_loss: 3.7292 - val_accuracy: 0.2958\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 37s 581ms/step - loss: 0.7290 - accuracy: 0.7806 - val_loss: 3.9756 - val_accuracy: 0.2745\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 36s 578ms/step - loss: 0.7201 - accuracy: 0.7827 - val_loss: 3.9243 - val_accuracy: 0.2885\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 35s 563ms/step - loss: 0.7141 - accuracy: 0.7869 - val_loss: 3.8342 - val_accuracy: 0.2802\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 36s 571ms/step - loss: 0.6955 - accuracy: 0.7893 - val_loss: 3.9509 - val_accuracy: 0.2953\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 36s 577ms/step - loss: 0.6904 - accuracy: 0.7936 - val_loss: 3.9024 - val_accuracy: 0.2958\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 36s 567ms/step - loss: 0.6554 - accuracy: 0.8001 - val_loss: 3.9210 - val_accuracy: 0.2875\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 36s 570ms/step - loss: 0.6570 - accuracy: 0.8027 - val_loss: 3.9457 - val_accuracy: 0.2901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f291dbdbc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-043X7CjODIM",
        "colab_type": "text"
      },
      "source": [
        "After allowing to train last layer of VGG16, we can see that the Training accuracy increased to around 80% but validation accuracy is still hovering around 29 to 30%.\n",
        "\n",
        "That means the model is overfitting on Training data but not performing well in general.\n",
        "\n",
        "To address this problem, we had already included BatchNormalization & Dropout Layers, but probably we need to increase the Dropout rate from 0.25 to 0.5 may be & check.\n",
        "\n",
        "Also, we can try making few more layers trainable because VGG16 was trained on different Objects out of which one might be Dog but definitely not it's breeds. But, that would increase the training time significantly & it is not easy to manage it on Google Colab because it gets disconnected from the GPU after inactivity & hence it cannot be simply allowed to leave it for training for huge amount of time.\n",
        "\n",
        "Another approach could be try using some advanced models like Googlenet, Resnet or Mobilenet."
      ]
    }
  ]
}